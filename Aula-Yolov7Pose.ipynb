{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86280,"status":"ok","timestamp":1713309045843,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"7aV1EcoC4JHO","outputId":"b3546963-5158-47d5-a21c-95485cb9247f"},"outputs":[],"source":["!pip install torch\n","!pip install torchvision\n","!pip install opencv-python\n","!pip install matplotlib\n","!pip install numpy"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1713309245786,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"brzwequYVTQO"},"outputs":[],"source":["\"\"\"\n","Pytorch é uma biblioteca de código aberto que fornece uma ampla gama de algoritmos de Machine Learning.\n","Torchvision é uma biblioteca que pode ser usada para transformações de imagem comuns em visão computacional.\n","Letterbox é uma função definida no módulo datasets do pacote utils. É usado para redimensionar uma imagem para uma dimensão específica sem alterar o aspecto original da imagem.\n","\"\"\"\n","\n","# importa bibliotecas necessárias, incluindo torch para deep learning e transforms para pré-processamento de imagem\n","import torch\n","from torchvision import transforms\n","from utils.datasets import letterbox\n","from utils.draw_kpts import desenhar_keypoints\n","\n","# importa bibliotecas para manipulação de imagens e gráficos\n","import numpy as np\n","import cv2\n","\n","# importa bibliotecas para medição de tempo e interação com o sistema\n","import time\n","import sys"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1713309249271,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"rGi8NZ4VSZt8","outputId":"f3c2716c-2fae-438d-d09d-ab335d0fcc85"},"outputs":[],"source":["# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\") # define o dispositivo de computação\n","\n","print(\"Dispositivo:\", device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1713309250430,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"QRLSNDW5Fsgx","outputId":"8603c96c-0b26-4be4-cbb1-85b8685a1694"},"outputs":[],"source":["print(\"Carregando modelo...\")\n","\n","# Carrega o modelo YOLOv7 pré-treinado e o coloca em modo de avaliação\n","# modelo = torch.hub.load('WongKinYiu/yolov7', 'yolov7-w6-pose.pt', pretrained=True, trust_repo=True, force_reload=True).autoshape()\n","modelo = torch.load('yolov7-w6-pose.pt', map_location=torch.device(device))['model']\n","modelo = modelo.to(device).float().eval()\n","\n","print(\"Modelo carregado!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90,"status":"ok","timestamp":1713309252199,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"M6fh_dIFFsyi","outputId":"1931e5a8-4114-49eb-9f82-58bf5c70a8ba"},"outputs":[],"source":["# Abre um vídeo para processamento\n","video_path = './dataset/video0.mp4'\n","print(\"Abrindo vídeo:\", video_path)\n","cap = cv2.VideoCapture(video_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1713309253258,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"L4o92mqXFs0h"},"outputs":[],"source":["if not cap.isOpened():\n","    print(\"Falha ao abrir o vídeo\")\n","    exit(1)\n","\n","# Lendo uma imagem para redimensiona-la\n","lido, imagem = cap.read()\n","\n","if not lido:\n","    sys.exit(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713309255385,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"vK-7WbrTFs2h"},"outputs":[],"source":["# Redimensionando imagem, sem a afetar a quantidade de detalhes dela\n","imagem_reduzida = letterbox(imagem, 512, stride=64, auto=True)[0]\n","# Capturando dimensões para criar um VideoWriter com estas dimensões\n","altura, largura, _ = imagem_reduzida.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713309256083,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"51y0XiDpFs4u"},"outputs":[],"source":["# Nome da imagem\n","nome_arquivo = f\"{video_path.split('/')[-1].split('.')[0]}\"\n","\n","# Definindo codec como MP4V\n","codec = cv2.VideoWriter_fourcc(*'mp4v')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1713309257153,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"Y5Ilw-vCF6kY"},"outputs":[],"source":["# Criando um VideoWriter para escrever vídeo de inferência com dimensôes da imaem que sofreu resize\n","output_video = cv2.VideoWriter(f\"./{nome_arquivo}_keypoints.mp4\", codec, 30, (largura, altura))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1713309257829,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"Vq_157BHF6mn","outputId":"7fd3d3ce-95ac-478e-c9cb-b8bff5dcc9ca"},"outputs":[],"source":["print(\"Vídeo foi aberto e suas informações como, altura e largura das imagens, foram definidas com sucesso!\")\n","\n","print(\"Começando inferência do modelo e escrita do vídeo de saída...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1713309259174,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"YJ13FFdIF6or"},"outputs":[],"source":["# inicializa contadores\n","frame_count = 0 # Contador de frames\n","total_fps = 0 # Total de frames por segundo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62734,"status":"ok","timestamp":1713309322840,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"TxLj_dznF6qV","outputId":"9420f2ad-bd66-4251-eb34-8ae995605967"},"outputs":[],"source":["while True:\n","    # Captura cada frame (frame) do video\n","    # ret é um bool que diz se o frame foi capturado ou não\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        break\n","\n","    # Capturando imagem original\n","    # Passando imagem na LetterBox Para o Resize\n","    imagem_redimensionada = letterbox(frame, 512, stride=64, auto=True)[0] # shape: (567, 960, 3) HWC\n","\n","    # tensor -> # torch.Size([3, 567, 960]) CHW\n","    # unsqueeze(0) -> transformação para batch (lote), torch.Size([1, 3, 567, 960]) 1 -> tamanho lote 1 imagem\n","    # Float() -> float32, aumenta a precisão dos números, o que é bom para CPU\n","    imagem_tensor = transforms.ToTensor()(imagem_redimensionada).unsqueeze(0).to(device).float()\n","\n","    # Marca o tempo de início e posteriormente o fim da inferência para calcular FPS\n","    start_time = time.time()\n","\n","    print(\"On frame:\", frame_count)\n","\n","    # Realiza a detecção de pose usando o modelo YOLOv7\n","    with torch.no_grad():\n","        \"\"\"\n","        model(image) -> retorna, coordenadas das bounding boxes, class predictions (previsões), e\n","        confidencia (float) para cada objeto detectado na imagem\n","        \"\"\"\n","        saida, _ = modelo(imagem_tensor)\n","\n","    end_time = time.time()\n","\n","    # calculando FPS\n","    fps = 1 / (end_time - start_time)\n","    total_fps += fps\n","\n","    frame_count += 1\n","\n","    # Escreve keypoints detectados em cada frame\n","    imagem_com_kpts = desenhar_keypoints(modelo, saida, imagem_redimensionada)\n","\n","    # Escreve FPS em frame\n","    # image = image.numpy().astype(np.uint8)\n","    cv2.putText(imagem_com_kpts, f\"{fps:.1f} FPS\", (15, 30), cv2.FONT_HERSHEY_SIMPLEX,\n","                1, (0, 255, 0), 2)\n","\n","    # Escreve imagem no vídeo de output\n","    output_video.write(imagem_com_kpts)\n","\n","# Libera captura do video de output\n","cap.release()\n","\n","# Fecha todos os frames e janelas do video\n","# cv2.destroyAllWindows()\n","\n","print(\"Vídeo escrito com sucesso!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1713309395251,"user":{"displayName":"arthur lima","userId":"06398003315782379190"},"user_tz":180},"id":"GP62mmmGGJ8K","outputId":"c357794b-4cdc-4d52-98a7-2d192728e2d1"},"outputs":[],"source":["# Calcula e retorna o FPS\n","avg_fps = total_fps / frame_count\n","\n","print(f\"Média de FPS: {avg_fps:.1f}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPerZN3RGaSCWWB3Akfl4II","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
